Giới thiệu về phân tích dữ liệu
phân tích dữ liệu
Trong một thế giới ngày càng tập trung xung quanh công nghệ thông tin, một lượng lớn dữ liệu được sản xuất và lưu trữ mỗi ngày. Thường thì những dữ liệu này đến từ hệ thống tự động phát hiện, cảm biến, và thiết bị khoa học, hoặc bạn tạo ra chúng hàng ngày và một cách vô thức mỗi khi bạn thực hiện rút tiền từ ngân hàng hoặc thực hiện mua hàng, khi bạn ghi lại trên các blog khác nhau, hoặc thậm chí khi bạn đăng trên xã hội mạng.
Tuy nhiên, dữ liệu là gì? Các dữ liệu thực sự không phải là thông tin, ít nhất là về mặt hình thức của họ. Trong dòng vô tướng của byte, thoạt nhìn rất khó để hiểu được bản chất của họ nếu không đúng số lượng, văn bản, hoặc thời gian mà họ báo cáo. Thông tin thực sự là kết quả của chế biến, trong đó có tính đến một tập hợp các dữ liệu, chiết xuất một số kết luận rằng có thể được sử dụng trong nhiều cách khác nhau. Quá trình chiết xuất thông tin từ dữ liệu thô chính là phân tích dữ liệu.
Mục đích của việc phân tích dữ liệu là chính xác để trích xuất thông tin đó không phải là dễ dàng deducible nhưng điều đó, khi hiểu, dẫn đến khả năng thực hiện các nghiên cứu về cơ chế của các hệ thống đó đã sản sinh ra chúng, do đó cho phép khả năng làm cho dự báo về phản ứng có thể của các hệ thống và quá trình tiến hóa của họ trong thời gian.
Bắt đầu từ một cách tiếp cận có phương pháp đơn giản về bảo vệ dữ liệu, phân tích dữ liệu đã trở thành một kỷ luật thật dẫn đến sự phát triển của các phương pháp thực tạo ra các mô hình. Mô hình này là trong thực tế, bản dịch sang một hình thức toán học của một hệ thống đặt dưới sự nghiên cứu. Khi đó là một hình thức toán học hay logic có thể để mô tả phản ứng hệ thống theo mức độ khác nhau của độ chính xác, bạn có thể đưa ra dự đoán về sự phát triển hoặc phản ứng của nó để đóng góp nhất định. Như vậy mục đích của phân tích dữ liệu không phải là mô hình, nhưng sự tốt lành của sức mạnh tiên đoán của nó.
Sức mạnh tiên đoán của một mô hình không chỉ phụ thuộc vào chất lượng của các kỹ thuật mô hình mà còn về khả năng lựa chọn một tập dữ liệu tốt trên đó để xây dựng toàn bộ phân tích dữ liệu. Vì vậy, việc tìm kiếm dữ liệu, khai thác của họ, và chuẩn bị tiếp theo của họ, trong khi đại diện cho hoạt động sơ bộ của một phân tích, cũng thuộc về phân tích dữ liệu chính nó, vì tầm quan trọng của họ trong sự thành công của các kết quả.
Cho đến nay chúng tôi đã nói đến dữ liệu, xử lý của họ, và chế biến của họ thông qua các thủ tục tính toán. Song song với tất cả các khâu chế biến của phân tích dữ liệu, phương pháp khác nhau của dữ liệu trực quan đã được phát triển. Trong thực tế, để hiểu được dữ liệu, cả cá nhân và về vai trò của họ trong toàn bộ tập dữ liệu, có hệ thống không tốt hơn so với phát triển các kỹ thuật của đại diện đồ họa có khả năng chuyển thông tin, đôi khi ngầm ẩn, trong con số, mà giúp bạn dễ dàng hiểu ý nghĩa của chúng. Trong những năm qua rất nhiều chế độ hiển thị đã được phát triển cho các chế độ khác nhau của màn hình dữ liệu: các bảng xếp hạng.
Vào cuối của phân tích dữ liệu, bạn sẽ có một mô hình và một bộ hiển thị đồ họa và sau đó bạn sẽ có thể để dự đoán phản ứng của hệ thống được nghiên cứu; sau đó, bạn sẽ chuyển sang giai đoạn thử nghiệm. Mô hình này sẽ được thử nghiệm sử dụng một tập hợp các dữ liệu mà chúng ta đã biết phản ứng của hệ thống. Những dữ liệu này được, tuy nhiên, không được sử dụng cho các định nghĩa của mô hình dự báo. Tùy thuộc vào khả năng của mô hình để tái tạo phản ứng thực quan sát, bạn sẽ có một tính toán sai lầm và kiến thức về tính hợp lệ của các mô hình và giới hạn hoạt động của nó.
Các kết quả này có thể được so sánh với bất kỳ mô hình khác để hiểu nếu một mới được tạo ra là hiệu quả hơn so với những cái hiện có. Một khi bạn đã đánh giá rằng, bạn có thể chuyển sang giai đoạn cuối cùng của dữ liệu phân tích-việc triển khai. Này bao gồm việc thực hiện các kết quả được sản xuất bởi các phân tích dữ liệu, cụ thể là, việc thực hiện các quyết định được đưa ra dựa trên những dự đoán tạo ra bởi các mô hình và những rủi ro mà một quyết định như vậy cũng sẽ được dự đoán.
Phân tích dữ liệu là một môn học đó là rất phù hợp với nhiều hoạt động chuyên nghiệp. Vì vậy, kiến thức về những gì nó là gì và làm thế nào nó có thể được đưa vào thực hiện sẽ có liên quan để củng cố các quyết định được thực hiện. Nó sẽ cho phép chúng tôi để kiểm tra giả thuyết, và để hiểu sâu hơn các hệ thống phân tích.
Tên miền Kiến thức vềChuyên viên phân tích dữ liệu
Phân tíchDữ liệu cơ bản là một kỷ luật phù hợp với việc nghiên cứu các vấn đề có thể xảy ra ở một số lĩnh vực ứng dụng. Hơn nữa, trong quá trình phân tích dữ liệu bạn có nhiều công cụ và phương pháp đòi hỏi phải có kiến thức tốt về máy tính và các khái niệm toán học và thống kê.
Vì vậy, một chuyên gia phân tích dữ liệu tốt phải có khả năng di chuyển và hoạt động trong nhiều lĩnh vực xử lý kỷ luật khác nhau. Nhiều người trong số những ngành là cơ sở của các phương pháp phân tích dữ liệu, và sự thành thạo trong số đó là gần như cần thiết. Kiến thức về các ngành khác là cần thiết tùy thuộc vào lĩnh vực ứng dụng và nghiên cứu của dự án phân tích dữ liệu cụ thể bạn muốn thực hiện, và tổng quát hơn, đủ kinh nghiệm trong các lĩnh vực chỉ có thể giúp bạn hiểu rõ hơn về các vấn đề và các loại dữ liệu cần thiết để bắt đầu với việc phân tích.
Thông thường, liên quan đến vấn đề chủ yếu của phân tích dữ liệu, nó là cần thiết để có một đội ngũ đa ngành của các chuyên gia tạo thành từ các thành viên tất cả đều có thể đóng góp theo cách tốt nhất có thể trong các lĩnh vực tương ứng của họ về thẩm quyền. Về vấn đề nhỏ hơn, một chuyên gia phân tích tốt phải có khả năng nhận ra các vấn đề phát sinh trong quá trình phân tích dữ liệu, tìm hiểu để tìm ra các nguyên tắc và kỹ năng cần thiết để giải quyết vấn đề, nghiên cứu các lĩnh vực, và thậm chí có thể hỏi những người am hiểu nhất trong lĩnh vực này. Nói tóm lại, các nhà phân tích phải có khả năng biết làm thế nào để tìm kiếm không chỉ cho dữ liệu, mà còn cung cấp thông tin về cách đối xử với họ.
Khoa học máy tính
Kiến thức về Khoa học Máy tính là một yêu cầu cơ bản đối với bất kỳ nhà phân tích dữ liệu. Trong thực tế, chỉ có một người có kiến thức tốt về kinh nghiệm và Khoa học Máy tính có khả năng quản lý hiệu quả các công cụ cần thiết cho việc phân tích dữ liệu. Trong thực tế, tất cả các bước liên quan đến việc phân tích dữ liệu liên quan đến việc sử dụng các công nghệ máy tính như phần mềm tính toán (chẳng hạn như IDL, Matlab, vv) và các ngôn ngữ lập trình (như C ++, Java, Python).
Lượng lớn có sẵn dữ liệu ngày nay nhờ vào công nghệ thông tin đòi hỏi kỹ năng cụ thể để có thể được quản lý một cách hiệu quả càng tốt. Trên thực tế, nghiên cứu dữ liệu và khai thác đòi hỏi kiến thức của các định dạng khác nhau. Các dữ liệu được cấu trúc và được lưu trữ trong các tập tin hoặc bảng cơ sở dữ liệu với các định dạng đặc biệt. XML, JSON, hoặc đơn giản là XLS hoặc các tập tin CSV hiện là định dạng phổ biến để lưu trữ và thu thập dữ liệu, và nhiều ứng dụng cũng cho phép đọc và quản lý dữ liệu được lưu trữ trên đó. Đối với việc khai thác dữ liệu chứa trong một cơ sở dữ liệu, điều này là không nên ngay lập tức, nhưng bạn cần phải biết ngôn ngữ truy vấn SQL hoặc sử dụng phần mềm đặc biệt được phát triển để tách dữ liệu từ một cơ sở dữ liệu nhất định.
Hơn nữa, đối với một số loại cụ thể của nghiên cứu dữ liệu, dữ liệu không có sẵn trong một định dạng trước điều trị và rõ ràng, nhưng có mặt trong các tập tin văn bản (văn bản, file log) hoặc trong các trang web, hiển thị như bảng xếp hạng, các biện pháp, số lượng khách truy cập , bảng hoặc HTML đòi hỏi chuyên môn kỹ thuật cụ thể cho các phân tích và khai thác cuối cùng của những dữ liệu này (Web Scraping).
Vì vậy, kiến thức về công nghệ thông tin là cần thiết để biết cách sử dụng các công cụ khác nhau tạo sẵn bởi khoa học máy tính hiện đại, chẳng hạn như các ứng dụng và các ngôn ngữ lập trình. Những công cụ này, đến lượt nó, là cần thiết để thực hiện các phân tích dữ liệu và dữ liệu trực quan.
Mục đích của cuốn sách này là chính xác để cung cấp tất cả các kiến thức cần thiết, càng xa càng tốt, liên quan đến sự phát triển của các phương pháp để phân tích dữ liệu sử dụng Python là một ngôn ngữ lập trình và các thư viện chuyên ngành cung cấp góp phần quyết định đến việc thực hiện tất cả các bước cấu thành phân tích dữ liệu, từ nghiên cứu dữ liệu để khai thác dữ liệu, lên đến nhận để công bố kết quả của mô hình dự báo.
Toán học và Thống kê
Như bạn sẽ thấy trong suốt cuốn sách, phân tích dữ liệu đòi hỏi rất nhiều môn toán, mà có thể khá phức tạp, trong quá trình điều trị và xử lý dữ liệu. Vì vậy, thẩm quyền trong tất cả điều này là cần thiết, ít nhất là để hiểu những gì bạn đang làm. Một số làm quen với các khái niệm thống kê chính cũng là cần thiết bởi vì tất cả các phương pháp được áp dụng trong phân tích và giải thích dữ liệu được dựa trên những khái niệm này. Cũng như bạn có thể nói rằng khoa học máy tính cung cấp cho bạn những công cụ để phân tích dữ liệu, vì vậy bạn có thể nói rằng số liệu thống kê cung cấp các khái niệm hình thành cơ sở của việc phân tích dữ liệu.
Nhiều là những công cụ và phương pháp kỷ luật này cung cấp cho các nhà phân tích, và một kiến thức tốt về làm thế nào để sử dụng chúng tốt nhất đòi hỏi nhiều năm kinh nghiệm. Trong số các kỹ thuật thống kê phổ biến nhất được sử dụng trong phân tích dữ liệu
Bayesiancác phương pháp
hồi quy
phân nhóm
Phải đối phó với những trường hợp này, bạn sẽ khám phá ra cách thức toán học và thống kê liên quan chặt chẽ với nhau, nhưng nhờ vào thư viện Python đặc biệt đề cập trong cuốn sách này, bạn sẽ có khả năng để quản lý và xử lý chúng.
Machine Learning và Trí tuệ nhân tạo
Một trong những công cụ tiên tiến nhất mà rơi vào phân tích dữ liệu là Machine Learning. Trong thực tế, mặc dù hình dung và kỹ thuật như phân nhóm và hồi quy, mà rất nhiều sẽ giúp chúng tôi để tìm thông tin về bộ dữ liệu của chúng tôi, trong giai đoạn này của nghiên cứu dữ liệu, bạn thường có thể thích sử dụng các thủ tục đặc biệt được đánh giá cao chuyên trong việc tìm kiếm mô hình trong tập dữ liệu.
Machine Learning là một kỷ luật mà làm cho sử dụng toàn bộ một loạt các thủ tục và các thuật toán mà phân tích dữ liệu để nhận mẫu, cụm, hoặc xu hướng và sau đó trích xuất thông tin hữu ích cho việc phân tích dữ liệu một cách hoàn toàn tự động.
Kỷ luật này đang ngày càng trở thành một công cụ cơ bản của phân tích dữ liệu, và do đó sự hiểu biết về nó, ít nhất là nói chung, có tầm quan trọng cơ bản cho các nhà phân tích dữ liệu.
Chuyên nghiệp Lĩnh vực ứng dụng
Một điểm rất quan trọng cũng là lĩnh vực thẩm quyền từ nơi dữ liệu đi (sinh học, vật lý, tài chính, vật liệu kiểm tra, thống kê về dân số, vv). Trong thực tế, mặc dù các nhà phân tích đã có sự chuẩn bị chuyên ngành trong lĩnh vực thống kê, ông cũng phải có khả năng đi sâu vào lĩnh vực ứng dụng và / hoặc tài liệu nguồn gốc của dữ liệu, với mục đích nhận thức và hiểu rõ hơn về cơ chế mà tạo dữ liệu. Trong thực tế, các dữ liệu không dây đơn giản hoặc số, nhưng họ là những biểu hiện, hay đúng hơn là biện pháp, của bất kỳ tham số quan sát. Như vậy, hiểu rõ hơn về lĩnh vực ứng dụng mà dữ liệu đến từ có thể cải thiện việc giải thích của họ. Thông thường, tuy nhiên, đây là quá tốn kém cho một nhà phân tích dữ liệu, thậm chí một với những ý định tốt nhất, và vì vậy nó là thực hành tốt để tìm chuyên gia tư vấn hoặc nhân vật chủ chốt mà bạn có thể đặt ra những câu hỏi đúng.
Hiểu bản chất của dữ liệu
Mục tiêu của nghiên cứu về phân tích dữ liệu về cơ bản là dữ liệu. Dữ liệu sau đó sẽ được các cầu thủ chủ chốt trong toàn bộ quá trình phân tích dữ liệu. Họ tạo thành nguyên liệu để được xử lý, và nhờ vào chế biến và phân tích của họ có thể trích xuất một loạt các thông tin để tăng mức độ hiểu biết về hệ thống được nghiên cứu, có nghĩa là, một từ mà các dữ liệu đến từ đâu.
Khi dữ liệu trở thành thông tin
dữ liệu là những sự kiện được ghi nhận trên thế giới. Bất cứ điều gì có thể đo được hoặc thậm chí phân loại có thể được chuyển đổi thành dữ liệu. Khi thu thập được, những dữ liệu này có thể được nghiên cứu và phân tích cả hai để hiểu bản chất của các sự kiện và rất thường xuyên cũng để đưa ra dự đoán hoặc ít nhất để đưa ra quyết định.
Khi thông tin trở thành kiến thức
Bạn có thể nói về kiến thức khi thông tin được chuyển thành một bộ quy tắc giúp bạn hiểu rõ hơn về cơ chế nhất định và do đó do đó, để đưa ra dự đoán về sự phát triển của một số sự kiện.
Các loại dữ liệu
Các dữ liệu có thể được chia thành hai loại khác nhau:
phân loại
danh nghĩa
thứ tự
số
rời rạc
tục
dữ liệu Categorical là các giá trị hoặc các quan sát có thể được chia thành các nhóm hoặc loại. Có hai loại giá trị phân loại: danh nghĩa và thứ tự. Một biến danh nghĩa không có trật tự nội tại được xác định trong thể loại của nó. Một biến thứ thay vì có một trật tự xác định trước.
Dữ liệu số là các giá trị hoặc các quan sát mà đến từ các phép đo. Có hai loại giá trị số khác nhau: số rời rạc và liên tục. Các giá trị rời rạc là những giá trị có thể được tính và không có nhiều khác biệt và tách rời nhau. Các giá trị liên tục, mặt khác, là những giá trị được tạo ra bởi phép đo hoặc quan sát cho rằng bất kỳ giá trị trong một phạm vi xác định.
Phân tích dữ liệu xử lý
phân tíchdữ liệu có thể được mô tả như một quá trình gồm nhiều bước, trong đó các dữ liệu thô được chuyển và xử lý để tạo ra hình ảnh dữ liệu và có thể đưa ra dự đoán nhờ vào một mô hình toán học dựa trên các dữ liệu thu thập được. Sau đó, phân tích dữ liệu là gì khác hơn là một chuỗi các bước, mỗi trong số đó đóng một vai trò then chốt trong những cái sau này. Vì vậy, phân tích dữ liệu gần như biểu đồ hóa như một chuỗi quá trình bao gồm các trình tự sau các giai đoạn:
Vấn đề định nghĩa
khai thác dữ liệu
dữ liệu làm sạch
dữ liệu chuyển đổi
thăm dò dữ liệu
Đoán mô hình
xác nhận mẫu / thử nghiệm
Visualization và giải thích kết quả
triển khai các giải pháp
phân tích xử lý dữ liệu
Vấn đề Definition
quá trình phân tích dữ liệu thực sự bắt đầu từ lâu trước khi tập hợp các dữ liệu thô. Trong thực tế, một phân tích dữ liệu luôn luôn bắt đầu với một vấn đề cần được giải quyết, mà cần phải được xác định.
Vấn đề được xác định chỉ sau khi bạn đã tốt tập trung vào hệ thống bạn muốn học: đây có thể là một cơ chế, một ứng dụng, hoặc một quá trình nói chung. Nói chung nghiên cứu này có thể để hiểu rõ hơn về hoạt động của mình, nhưng đặc biệt là nghiên cứu này sẽ được thiết kế để hiểu các nguyên tắc ứng xử của nó để có thể đưa ra dự đoán, hoặc đưa ra lựa chọn (được định nghĩa như một sự lựa chọn thông).
Bước định nghĩa và các tài liệu tương ứng (phân phôi) của vấn đề khoa học hay kinh doanh đều rất quan trọng để tập trung toàn bộ phân tích nghiêm ngặt trên nhận được kết quả. Trong thực tế, một nghiên cứu toàn diện hoặc đầy đủ của hệ thống là đôi khi phức tạp và bạn không phải lúc nào cũng có đủ thông tin để bắt đầu. Vì vậy, định nghĩa của vấn đề và đặc biệt là kế hoạch của nó có thể xác định duy nhất các hướng dẫn để làm theo cho toàn bộ dự án.
Một khi vấn đề đã được xác định và ghi nhận, bạn có thể di chuyển đến dự án planningof một phân tích dữ liệu. Kế hoạch là cần thiết để hiểu được các chuyên gia và các nguồn lực cần thiết để đáp ứng các yêu cầu để thực hiện dự án một cách hiệu quả càng tốt. Vì vậy, bạn sẽ phải xem xét các vấn đề trong khu vực liên quan đến việc giải quyết các vấn đề. Bạn sẽ tìm kiếm các chuyên gia trong nhiều lĩnh vực quan tâm và cuối cùng là cài đặt phần mềm cần thiết để thực hiện các phân tích dữ liệu.
Như vậy, trong giai đoạn quy hoạch, lựa chọn một nhóm hiệu quả diễn ra. Nói chung, các đội nên liên ngành để giải quyết vấn đề bằng cách nhìn vào các dữ liệu từ nhiều góc độ khác nhau. Vì vậy, sự lựa chọn của một đội bóng tốt chắc chắn là một trong những yếu tố quan trọng dẫn đến thành công trong việc phân tích dữ liệu.
Khai thác dữ liệu
Một khi vấn đề đã được xác định, bước đầu tiên là để có được những dữ liệu để thực hiện các phân tích. Các dữ liệu phải được lựa chọn với mục đích cơ bản của việc xây dựng các mô hình tiên đoán, và do đó lựa chọn của họ là rất quan trọng cho sự thành công của việc phân tích là tốt. Các dữ liệu thu thập mẫu phải thể hiện càng nhiều càng tốt thế giới thực, có nghĩa là, làm thế nào hệ thống phản ứng với các kích thích từ thế giới thực. Trong thực tế, thậm chí sử dụng bộ dữ liệu khổng lồ của dữ liệu thô, thường xuyên, nếu không được thu thập thành thạo, chúng có thể miêu tả các tình huống sai lệch hoặc không cân bằng so với những cái thực tế.
Do đó, một sự lựa chọn nghèo của dữ liệu, hoặc phân tích thậm chí thực hiện trên một tập hợp dữ liệu mà không phải là hoàn toàn đại diện của hệ thống, sẽ dẫn đến các mô hình sẽ di chuyển ra khỏi hệ thống được nghiên cứu.
Việc tìm kiếm và truy xuất dữ liệu thường đòi hỏi một hình thức trực giác mà đi xa hơn việc nghiên cứu và dữ liệu kỹ thuật khai thác đơn thuần. Nó cũng đòi hỏi một sự hiểu biết kỹ lưỡng về bản chất của dữ liệu và hình thức của họ, mà chỉ kinh nghiệm tốt và kiến thức trong lĩnh vực ứng dụng của vấn đề có thể cung cấp.
Không phụ thuộc vào chất lượng và số lượng dữ liệu cần thiết, một vấn đề khác là việc tìm kiếm và lựa chọn chính xác của nguồn dữ liệu.
Nếu môi trường studio là một phòng thí nghiệm (kỹ thuật hay khoa học), và các dữ liệu được tạo ra tính chất thử nghiệm, sau đó trong trường hợp này các nguồn dữ liệu có thể dễ dàng nhận biết. Trong trường hợp này, các vấn đề sẽ chỉ liên quan đến việc thiết lập thử nghiệm.
Nhưng nó không phải là có thể cho phân tích dữ liệu để tái tạo hệ thống trong đó dữ liệu được thu thập một cách nghiêm chỉnh thực nghiệm trong mọi lĩnh vực ứng dụng. Nhiều lĩnh vực ứng dụng yêu cầu tìm kiếm dữ liệu từ thế giới xung quanh, thường dựa trên dữ liệu thực nghiệm bên ngoài, hoặc thậm chí thường xuyên hơn thu thập chúng thông qua phỏng vấn hoặc khảo sát. Vì vậy, trong những trường hợp này, việc tìm kiếm một nguồn dữ liệu tốt mà có thể cung cấp tất cả các thông tin cần thiết cho việc phân tích dữ liệu có thể được khá khó khăn. Thông thường nó là cần thiết để lấy dữ liệu từ nhiều nguồn dữ liệu để bổ sung bất kỳ thiếu sót, để xác định bất kỳ sự khác biệt, và để làm cho dữ liệu của chúng tôi thiết lập như chung càng tốt.
Khi bạn muốn để có được các dữ liệu, một nơi tốt để bắt đầu là chỉ Web. Nhưng hầu hết các dữ liệu trên Web có thể khó khăn để nắm bắt; trên thực tế, không phải tất cả dữ liệu có sẵn trong một tập tin hoặc cơ sở dữ liệu, nhưng có thể nhiều hơn hoặc ít ngầm nội dung bên trong các trang HTML trong nhiều định dạng khác nhau. Để kết thúc này, một phương pháp được gọi là Web Scraping, cho phép thu thập dữ liệu thông qua việc công nhận xảy ra cụ thể của các thẻ HTML trong trang web, đã được phát triển. Có phần mềm được thiết kế đặc biệt cho mục đích này, và một khi xảy ra được tìm thấy, họ trích xuất các dữ liệu mong muốn. Khi tìm kiếm hoàn tất, bạn sẽ nhận được một danh sách các dữ liệu sẵn sàng để được chịu sự phân tích dữ liệu.
Chuẩn bị dữ liệu
Trong số tất cả các bước liên quan trong phân tích dữ liệu, chuẩn bị dữ liệu, mặc dù dường như ít có vấn đề, trên thực tế là một trong những đòi hỏi nhiều nguồn lực và thời gian hơn để hoàn thành. Các dữ liệu thu thập được thường xuyên thu thập từ các nguồn dữ liệu khác nhau, mỗi trong số đó sẽ có các dữ liệu trong nó với một đại diện khác nhau và định dạng. Vì vậy, tất cả các dữ liệu sẽ phải được chuẩn bị cho quá trình phân tích dữ liệu.
Việc chuẩn bị các dữ liệu liên quan đến việc thu thập, làm sạch, bình thường hóa, và chuyển dữ liệu vào một tập hợp dữ liệu được tối ưu hóa, có nghĩa là, trong một định dạng chuẩn bị, thông thường bảng, thích hợp cho các phương pháp phân tích đã được lên kế hoạch trong giai đoạn thiết kế.
Nhiều là những vấn đề cần phải tránh được, chẳng hạn như các giá trị không hợp lệ, không rõ ràng, hoặc mất tích, lĩnh vực nhân rộng, hoặc dữ liệu out-of-range.
Dữ liệu thăm dò / Visualization
Khám phá dữ liệu về bản chất là việc tìm kiếm dữ liệu trong một bài thuyết trình đồ họa hoặc thống kê để tìm ra mô hình, kết nối, và các mối quan hệ trong dữ liệu. Trực quan dữ liệu là công cụ tốt nhất để làm nổi bật mẫu càng tốt.
Trong những năm gần đây, dữ liệu trực quan đã được phát triển đến mức độ như vậy mà nó đã trở thành một kỷ luật thực của riêng mình. Trong thực tế, rất nhiều công nghệ được sử dụng dành riêng cho màn hình hiển thị của dữ liệu, và không kém phần nhiều là các loại màn hình áp dụng để trích xuất các thông tin tốt nhất có thể từ một tập dữ liệu.
Thăm dò dữ liệu bao gồm một cuộc kiểm tra sơ bộ các dữ liệu, đó là quan trọng để hiểu các loại thông tin đã được thu thập và ý nghĩa của chúng. Trong sự kết hợp với các thông tin thu được trong vấn đề định nghĩa, phân loại này sẽ xác định phương pháp phân tích dữ liệu sẽ là phù hợp nhất cho đến lúc một định nghĩa mô hình.
Nói chung, giai đoạn này, ngoài một nghiên cứu chi tiết của bảng xếp hạng qua các dữ liệu trực quan, có thể bao gồm một hoặc nhiều các hoạt động sau:
Tóm tắt dữ liệu
theo nhóm dữ liệu
thăm dò về mối quan hệ giữa các thuộc tính khác nhau
Xác định mô hình và xu hướng
xây dựng các mô hình hồi quy
xây dựng các mô hình phân loại
chung, phân tích dữ liệu đòi hỏi quá trình tổng hợp các báo cáo liên quan đến các dữ liệu được nghiên cứu. Tổng kết là một quá trình mà qua đó dữ liệu được giảm xuống còn giải thích mà không bị mất thông tin quan trọng.
Clustering là một phương pháp phân tích dữ liệu được sử dụng để tìm các nhóm đoàn kết bởi các thuộc tính chung (nhóm).
Một bước quan trọng của việc phân tích tập trung vào việc xác định các mối quan hệ, xu hướng và sự bất thường trong dữ liệu. Để tìm hiểu loại thông tin này, người ta thường phải dùng đến các công cụ cũng như thực hiện một đợt phân tích dữ liệu, thời gian này trên trực quan dữ liệu riêng của mình.
Các phương pháp khác của khai thác dữ liệu, chẳng hạn như cây quyết định và luật kết hợp, tự động trích xuất dữ kiện quan trọng hoặc quy tắc từ dữ liệu. Những cách tiếp cận có thể được sử dụng song song với hình dung dữ liệu để tìm thông tin về các mối quan hệ giữa các dữ liệu.
dự báo mô hình
Xây dựng mô hình tiên đoán là một quá trình được sử dụng trong phân tích dữ liệu để tạo hoặc chọn một mô hình thống kê phù hợp với dự đoán xác suất của một kết quả.
Sau khi khám phá dữ liệu bạn có tất cả các thông tin cần thiết để phát triển các mô hình toán học mà mã hóa mối quan hệ giữa các dữ liệu. Những mô hình này rất hữu ích trong việc tìm hiểu hệ thống được nghiên cứu, và theo một cách cụ thể mà họ được sử dụng cho hai mục đích chính. Đầu tiên là để đưa ra dự đoán về các giá trị dữ liệu được tạo ra bởi hệ thống; trong trường hợp này, bạn sẽ được xử lý với các mô hình hồi quy. Thứ hai là để phân loại các sản phẩm dữ liệu mới, và trong trường hợp này, bạn sẽ sử dụng mô hình phân loại hoặc các mô hình clustering. Trong thực tế, người ta có thể chia các mô hình theo loại kết quả mà họ sản xuất:
mô hình Phân loại: Nếu kết quả thu được bằng các loại mô hình là phân loại.
Mô hình hồi quy: Nếu kết quả thu được bằng các loại mô hình là số.
Mô hình Clustering: Nếu kết quả thu được bằng các loại mô hình là mô tả.
Phương pháp đơn giản để tạo ra các mô hình này bao gồm các kỹ thuật như hồi quy tuyến tính, hồi quy logistic, phân loại và hồi quy cây, và k-khu vực gần xóm. Nhưng các phương pháp phân tích rất nhiều, và mỗi người đều có những đặc điểm riêng mà làm cho nó tuyệt vời đối với một số loại dữ liệu và phân tích. Mỗi phương pháp này sẽ tạo ra một mô hình cụ thể, và sau đó lựa chọn của họ là có liên quan đối với bản chất của mô hình sản phẩm.
Một số các mô hình này sẽ cung cấp các giá trị tương ứng với hệ thống sản, và cũng theo cấu trúc của họ, họ sẽ giải thích một số đặc điểm của hệ thống được nghiên cứu một cách đơn giản và rõ ràng. Các mô hình khác sẽ tiếp tục cung cấp cho dự đoán tốt, nhưng cấu trúc của chúng sẽ không có nhiều hơn một “hộp đen” với khả năng hạn chế để giải thích một số đặc điểm của hệ thống.
Mô hình Validation
Validation của mô hình, đó là, giai đoạn thử nghiệm, là một giai đoạn quan trọng mà cho phép bạn xác nhận các mô hình được xây dựng trên cơ sở bắt đầu dữ liệu. Đó là điều quan trọng vì nó cho phép bạn để đánh giá tính hợp lệ của dữ liệu được tạo ra bởi các mô hình bằng cách so sánh trực tiếp với hệ thống thực tế. Nhưng lần này, bạn đang sắp ra khỏi tập hợp bắt đầu từ dữ liệu trên đó toàn bộ phân tích đã được thành lập.
Nói chung, bạn sẽ tham khảo các dữ liệu như tập huấn luyện, khi bạn đang sử dụng chúng để xây dựng mô hình, và như các thiết lập xác nhận, khi bạn đang sử dụng chúng để phê chuẩn mô hình.
Như vậy, bằng cách so sánh các dữ liệu được tạo ra bởi các mô hình với những sản phẩm của hệ thống, bạn sẽ có thể đánh giá sai số, và sử dụng bộ dữ liệu thử nghiệm khác nhau, bạn có thể ước tính các giới hạn hiệu lực của mô hình được tạo ra. Trong thực tế, giá trị tiên đoán một cách chính xác có thể chỉ có giá trị trong một phạm vi nhất định, hoặc có mức độ khác nhau của khớp tùy thuộc vào phạm vi của các giá trị đưa vào tính toán.
Quá trình này cho phép bạn không chỉ để số lượng đánh giá hiệu quả của mô hình mà còn để so sánh nó với bất kỳ mô hình hiện có khác. Có một số kỹ thuật trong lĩnh vực này; nổi tiếng nhất là cross-validation. Kỹ thuật này được dựa trên sự phân chia công tác đào tạo thiết lập thành nhiều phần khác nhau. Mỗi một phần, đến lượt nó, sẽ được sử dụng như các thiết lập thẩm định và bất kỳ khác như tập huấn luyện. Bằng cách lặp đi lặp lại này, bạn sẽ có một mô hình ngày càng hoàn thiện.
Triển khai
này là bước cuối cùng của quá trình phân tích, nhằm trình bày các kết quả, có nghĩa là, các kết luận của phân tích. Trong quá trình triển khai, trong môi trường kinh doanh, phân tích được dịch sang một lợi ích cho khách hàng đã ủy thác nó. Trong môi trường kỹ thuật hoặc khoa học, nó được dịch sang các giải pháp thiết kế hoặc các ấn phẩm khoa học. Đó là, việc triển khai cơ bản bao gồm việc đưa vào thực tế kết quả thu được từ việc phân tích dữ liệu.
Có một số cách để triển khai kết quả của một phân tích dữ liệu hoặc khai thác dữ liệu. Thông thường, việc triển khai một chuyên gia phân tích dữ liệu của bao gồm bằng văn bản một báo cáo cho quản lý hoặc cho các khách hàng yêu cầu phân tích. Tài liệu này sẽ khái niệm mô tả các kết quả thu được từ việc phân tích dữ liệu. Báo cáo cần được hướng dẫn để các nhà quản lý, những người sau đó có thể đưa ra quyết định. Sau đó, họ sẽ thực sự đưa vào thực hiện kết luận của phân tích.
Trong các tài liệu được cung cấp bởi các nhà phân tích, mỗi người trong số bốn chủ đề nói chung sẽ được thảo luận chi tiết:
Kết quả phân tích
Quyết định triển khai
Phân tích rủi ro
đo lường tác động kinh doanh
Khi kết quả của dự án bao gồm việc tạo ra mô hình tiên đoán, các mô hình này có thể được triển khai như một độc lập ứng dụng hoặc có thể được tích hợp trong phần mềm khác.
định lượng và định tính dữ liệu phân tích
Do đó phân tích Dữ liệu là một quá trình hoàn toàn tập trung vào dữ liệu, và, tùy theo tính chất của dữ liệu, nó có thể làm cho một số khác biệt.
Khi dữ liệu phân tích có một cấu trúc số đúng hoặc phân loại, sau đó bạn đang nói về phân tích định lượng, nhưng khi bạn đang đối phó với giá trị được thể hiện qua mô tả trong ngôn ngữ tự nhiên, sau đó bạn đang nói về phân tích định tính.
Chính vì tính chất khác nhau của dữ liệu được xử lý bởi hai loại phân tích, bạn có thể quan sát một số khác biệt giữa chúng.
Phân tích định lượng đã làm với dữ liệu có một trật tự logic trong họ, hoặc có thể được phân loại một cách nào đó. Điều này dẫn đến sự hình thành của các cấu trúc trong dữ liệu. Trình tự, phân loại, và các cấu trúc lần lượt cung cấp thêm thông tin và cho phép tiếp tục xử lý các dữ liệu một cách chặt chẽ toán học hơn. Điều này dẫn đến việc tạo ra mô hình có thể cung cấp những dự đoán định lượng, do đó cho phép các nhà phân tích dữ liệu để rút ra kết luận khách quan hơn.
Phân tích định tính thay vì phải làm gì với dữ liệu mà thường không có một cấu trúc, ít nhất là không phải một mà là điều hiển nhiên, và bản chất của chúng không phải là số hay phân loại. Ví dụ, dữ liệu cho việc nghiên cứu định tính có thể bao gồm văn bản, hình ảnh, hoặc dữ liệu âm thanh bằng văn bản. Đây là loại phân tích do đó phải căn cứ vào phương pháp, thường ad hoc, để trích xuất thông tin mà thường sẽ dẫn đến mô hình có khả năng cung cấp các dự báo định tính, với kết quả là kết luận mà các nhà phân tích dữ liệu có thể đến cũng có thể bao gồm giải thích chủ quan. Mặt khác, phân tích định tính có thể khám phá các hệ thống phức tạp hơn và rút ra kết luận đó là không thể với một cách tiếp cận đúng toán học. Thông thường kiểu phân tích này liên quan đến việc nghiên cứu về hệ thống như hiện tượng xã hội hoặc cấu trúc phức tạp mà không phải là dễ dàng đo lường được.
Hình 1-2 cho thấy sự khác biệt giữa hai loại phân tích:
Open image in new window
Hình 1-2.
Định lượng và phân tích
dữ liệu mở
Để hỗ trợ các nhu cầu ngày càng tăng về dữ liệu, một số lượng lớn các nguồn dữ liệu đang có sẵn trong Internet. Những nguồn dữ liệu cung cấp thông tin tự do cho bất cứ ai có nhu cầu, và chúng được gọi là mở dữ liệu.
Dưới đây là danh sách một số dữ liệu mở có sẵn trực tuyến. Bạn có thể tìm thấy một danh sách đầy đủ hơn và chi tiết của dữ liệu mở trực tuyến có sẵn tại Phụ lục B.
DataHub (http://datahub.io/dataset)
Tổ chức Y tế Thế giới (http://www.who.int/research/en/)
Data.gov (http://data.gov)
Liên minh châu  u dữ liệu mở Portal (http://open-data.europa.eu/en/data/)
bộ dữ liệu công cộng Amazon Web Service (http://aws.amazon.com / bộ dữ liệu)
Facebook Graph (http://developers.facebook.com/docs/graph-api)
Healthdata.gov (http://www.healthdata.gov)
Google Trends (http: //www.google.com.ezproxy .library.ubc.ca / xu hướng / khám phá)
Google Finance (https://www-google-com.ezproxy.library.ubc.ca/finance)
Google Sách Ngrams (http://storage.googleapis.com/books/ ngrams / sách / datasetsv2.html)
Machine Learning Repository (http://archive.ics.uci.edu/ml/)
về vấn đề này, để cung cấp cho một ý tưởng về nguồn dữ liệu mở có sẵn trên mạng, bạn có thể nhìn vào sơ đồ mây LOD (http://lod-cloud.net), hiển thị tất cả các kết nối của liên kết dữ liệu giữa nhiều nguồn dữ liệu mở c urrently sẵn trong mạng (xem hình 1-3).
Liên kết Sơ đồ đám mây mở dữ liệu năm 2014, bởi Max Schmachtenberg, Christian Bizer, Anja JENTZSCH, và Richard Cyganiak. http://lod-cloud.net/ [CC-BY-SA giấy phép]
Python và phân tích dữ liệu
Lập luận chính của cuốn sách này là phát triển tất cả các khái niệm về phân tích dữ liệu bằng cách đối xử với họ về Python. Python là một ngôn ngữ lập trình sử dụng rộng rãi trong giới khoa học vì số lượng lớn của các thư viện cung cấp một bộ đầy đủ các công cụ để phân tích và thao tác dữ liệu.
So với ngôn ngữ lập trình khác thường được sử dụng để phân tích dữ liệu, chẳng hạn như R và Matlab, Python không chỉ cung cấp một nền tảng cho quá trình xử lý dữ liệu nhưng cũng có một số tính năng mà làm cho nó độc đáo so với các ngôn ngữ khác và các ứng dụng chuyên ngành. Sự phát triển của một số lượng ngày càng tăng của các thư viện hỗ trợ, việc thực hiện các thuật toán của phương pháp sáng tạo hơn, và khả năng giao tiếp với ngôn ngữ lập trình khác (C và Fortran) làm Python duy nhất trong số loại hình này.
Bên cạnh đó, Python không chỉ chuyên cho việc phân tích dữ liệu, nhưng cũng có rất nhiều các ứng dụng khác, chẳng hạn như chương trình chung, kịch bản, interfacing đến cơ sở dữ liệu, và gần đây hơn là phát triển web là tốt, nhờ vào các khuôn khổ web như Django. Vì vậy, nó có thể phát triển các dự án phân tích dữ liệu mà là hoàn toàn tương thích với các máy chủ web với khả năng tích hợp nó trên Web.
Vì vậy, đối với những người muốn thực hiện phân tích dữ liệu, Python, với tất cả các gói của nó, có thể được coi là sự lựa chọn tốt nhất cho tương lai gần.
Kết luận
Trong chương này, bạn đã thấy những gì phân tích dữ liệu là gì và cụ thể hơn là các quá trình khác nhau mà bao gồm nó. Also, you have begun to see the role played by data in building a prediction model and how their careful selection is at the basis of a careful and accurate data analysis.
In the next chapter, take you will take this vision of Python and the tools it provides to perform data analysis.
